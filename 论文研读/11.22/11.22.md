# Towards Large-Scale Small Object Detection:Survey and Benchmarks 的研读、对第V部分进行细致解读 11.08
## 名词
### Benchmarks 来自标题
Benchmark 在机器学习里的定义：

>Benchmarking measures performance using a specific indicator, resulting in a metric that is then compared to others.Key performance indicators typically measured here are **data capacity, training speed, inference speed, and model precision**.

"Benchmark" 允许我们以客观的方式测量不同算法、模型或方法在特定任务上的表现，就像比较两种产品的性能一样。在机器学习中，"Benchmark"（基准测试）通常指的是一种对算法、模型或方法性能的标准化评估和比较方法。这是一种重要的工具，用于衡量和比较不同机器学习算法或模型的表现，以确定哪个方法在特定任务或数据集上表现最佳。
### Small Object Detection (SOD)
来自Abstract
>Then,to catalyze the development of SOD, we construct two large-scale Small Object Detection dAtasets(SODA), SODA-D and SODA-A, which focus on the **Driving and Aerial scenarios** respectively

用两个数据集分别针对驾驶和空中场景
#### convolutional neural networks 卷积神经网络

### IoU（Intersection over Union）II.A

   >是一种用于衡量目标检测算法性能的常用指标。它通过计算两个边界框（通常是一个预测的边界框和一个真实的边界框）之间的重叠程度来评估检测结果的准确性。

IoU的计算方法是将两个边界框的交集面积除以它们的并集面积。公式如下：

IoU=预测框∩真实框预测框∪真实框IoU=预测框∪真实框预测框∩真实框?

这个值的范围在0到1之间，表示了两个框重叠的程度。IoU值越高，表示两个边界框之间的重叠越大，通常用来衡量预测框与真实框之间的匹配程度。在目标检测任务中，一般IoU达到一定的阈值（如0.5或0.75）会被认为是一个成功的检测结果。
 
## I. Introduction
### A.Problem Definition
>Object detection aims to classify and locate instances. the terms tiny and small are typically defined by an area threshold  or length threshold 

目标检测目的为分类与定位实例。
物体的“小”由面积阈值或长度阈值定义
### B. Comparisons With Previous Reviews
before:
>concentrate on either generic object detection or specific object detection task such as pedestrian detection
大多数先前的综述(如表I所示)集中在通用目标检测[13],[14],[15]或特定目标检测任务，如行人检测[16],[17],文本检测[18],遥感图像中的检测[19],[20]和交通场景下的检测[21],[22]等。
now:
>we provide a systematic survey of small object detection and an understandable and highly structured taxonomy(分类法), which organizes SOD approaches into six major categories based on the techniques involved and is radically different from previous ones.

### conclusion
the main contributions of this paper 
1. **Reviewing** the development of small object detection in the deep-learning era and providing a systematic survey of the recent progress in this field, which can be grouped into **six categories**:
   > sample-oriented methods, scale-aware methods,attention-based methods, feature-imitation methods, context modeling methods, and focus-and-detect approaches.
2. **Releasing two large-scale benchmarks** for small object detection, where the first one was dedicated to driving scenarios and the other was specialized for aerial scenes.
3. **Investigating the performance** of several representative object detection methods on our datasets
## II. REVIEW ON SMALL OBJECT DETECTION
### A. Main Challenges
#### 1. object information loss
   >Such information loss will scarcely impair the performance of large or medium-sized objects to a certain extent, considering that the final features still retain enough information of them. Unfortunately, this is fatal for small objects, because the detection head can **hardly give accurate predictions** on top of the highly structural representations, in which the weak signals of small objects were almost wiped out.

#### 2. noisy feature representation
   >To sum up, the feature representations of small objects are apt to suffer from the noise, hindering the subsequent detection.

#### 3. low tolerance for bounding box perturbation and inadequate samples.(对边界框扰动的低容忍度和样本不足)
   >Union(IoU) metric was adopted to evaluate the accuracy. 
   IoU表示真实框与相关预测框之间的交集比联合。

   - **对边界框扰动的低容忍度**：目标检测中的一个主要任务是定位，它在大多数检测范式中被构建为回归问题。
   >As shown inFig. 1, a slight deviation (6 pixels along the diagonal direction)of predicted box for a small object causes significant drop onIoU (from 100% to 32.5%) compared to medium and large objects (56.6% and 71.8%). Meanwhile, a greater variance (say, 12 pixels) further exacerbates the situation, and the IoU drops to poorly 8.7% for small objects
   ![Fig.1](D:\桌面\Fig.1.png)
   
   这表明，与大目标相比，小目标对边界框扰动的容忍度较低，加剧了回归分支的学习困难。

   - **训练样本不足**：选择正负样本是训练高性能检测器不可或缺的步骤。
   >positive and negative samples:在机器学习中，特别是在目标检测任务中，为了训练模型，需要从数据集中选择具有代表性的   **正样本**(*包含目标*)和负样本（*不包含目标*）。选择这些样本是为了让模型学习如何区分目标和非目标，从而实现准确的目标检测。选择不足的样本可能会导致模型训练不充分，影响最终检测器的性能和准确度。

   > Concretely, small instances occupy fairly small regions and have limited overlaps to priors (anchors or points). 
   
   这对传统的标签分配策略构成了巨大挑战，这些策略是基于边界框或中心区域的重叠来收集正负样本的，导致在训练过程中分配给小目标的正样本不足。

### B. Review of Small Object Detection Algorithms
   基于深度学习的通用目标检测方法可以分为两类：两阶段和单阶段检测，前者通过粗到细的步骤进行目标检测，而后者则一次性完成检测。
   -  detection head
   >在目标检测中，"detection heads"（检测头部）通常指的是神经网络模型的最后几层或特定部分，专门用于处理生成的特征，并执行目标检测的关键步骤，如分类和定位。这些头部层可以理解为网络结构的一部分，接受来自前面层（通常是提取的特征图）的信息，并进行最终的目标分类和定位。 
#### 1. 两阶段目标检测方法
   
   在两阶段目标检测方法中，首先通过一些机制（如Region Proposal Network-RPN）生成候选区域，然后这些区域的特征被传递到检测头部进行最终的目标分类和边界框回归。 
#### 2. 一阶段方法
   
   在一阶段方法中，网络直接在密集的**锚点或网格**上执行检测，并直接预测分类分数和坐标。**由于不需要生成候选区域，一阶段检测器在计算效率上表现出优势，但通常在准确性上稍显落后.**

   为了解决小目标检测中的挑战性问题，现有的方法通常在通用目标检测的强大范式中引入刻意设计。
#### 3.1 Sample-Oriented Methods 样本取样方法
   
   > 困境：一是当前数据集中尺寸较小的目标只占据了一小部分区域；二是基于重叠的匹配方法对于样本提取过于严格，无法采样到足够的正向锚点或点，因为先验框与小目标区域之间的重叠有限。主要分为以下两个方向:
   
##### *数据增强策略：*

   - 一些方法如Kisantal等人的工作通过将小目标进行复制，并在同一图像中的不同位置进行随机变换来增广小实例。
   - RRNet引入了AdaResampling，利用先验分割图来指导有效位置的抽样过程，进一步减少了粘贴对象的尺度差异。
   - Zhang等人和Wang等人使用了基于分割的操作来获得更多小目标的训练样本，例如分割、图像修复和图像融合等。

##### *优化的标签分配：*

   - 另一些方法通过优化标签分配策略来改善重叠或距离匹配策略带来的子优采样结果，并减少回归过程中的扰动。
   - 例如，S3FD通过设计的尺度补偿锚点匹配策略增加了微小人脸的匹配锚点，从而提高了召回率。
   - Zhu等人提出了Expected Max Overlapping（EMO）分数，考虑了锚点步长在计算重叠时的影响，为小人脸提供更好的锚点设置。
   - 还有其他方法，比如DotD、RFLA等，都采用了不同的方式来改进标签分配策略，提高主流检测器在小目标上的性能表现。

#### 3.2 Scale-Aware Methods 尺度感知方法
   尺度变化可能非常显著，导致同一个检测器面临着不同的检测难题
   > the following works mainly follow two paths. 
   - __multi-branch architecture or tailored training scheme__ 设计多支路架构或定制训练方案来构建特定尺度的检测器
   - __fuse the hierarchical features__ 将分层特征进行融合 for powerful representations of small objects.
   Both of these approaches actually minimize the information loss during feature extraction to a certain extent.

##### *Scale-Specific Detectors:尺度特定检测器*
   - The nature behind this line is simple: 不同深度或级别的特征负责检测相应尺度的物体。
   - 如利用尺度相关池化（SDP）选择适合小目标的特征层进行池化操作，或者在不同中间层生成物体提议，每个层专注于特定尺度范围内的物体。这种方法通过在不同尺度上产生多尺度预测，使高分辨率特征负责小目标，从而提高了小目标检测的效果。
  
   > **尺度相关池化(SDP)** 
   是一种针对不同尺度目标的特定池化操作。它的主要目的是为了在特征图的不同深度或层级上进行池化操作，以便更有效地处理不同尺度物体的特征信息。通过尺度相关池化，可以选择性地对不同尺度的特征图进行处理，使得针对不同尺度目标的特征能够更好地被模型所利用。这种池化方法有助于提高对小目标或大目标等不同尺度目标的检测精度。

   >**在不同中间层生成物体提议**
   指的是一种生成物体提议（通常是候选区域或感兴趣区域）的方法，该方法是基于深度神经网络中的不同中间层次来产生针对不同尺度的物体提议。通常，深度神经网络会在不同深度产生不同级别、不同分辨率的特征图，这些特征图对应着不同层次的语义信息和图像细节。在物体检测中，利用这些不同层次的特征图可以产生不同尺度的物体提议，使得模型能够更好地适应不同尺度目标的检测需求。这样的方法可以增加模型对不同尺度物体的感知能力，并提高检测的准确性。

##### *Hierarchical Feature Fusion：层级特征融合的方法*
   - 困境：在小目标检测任务中，深层特征可能难以捕捉到小物体的响应，而早期阶段的特征图则容易受到光照、变形和物体姿态等因素的影响，使得分类任务更加具有挑战性。
   - 采用特征融合的方法，即集成不同深度的特征，以获得更好的小目标特征表示。
   - 如PANet、BiFPN等，以增强深层特征并提高其对准确定位的信号的敏感性。其他方法如Zhang等人提出的多深度RoI特征汇聚、Woo等人的StairNet、M2Det中的并行分支、IPG-Net的IPG变换模块、Gong等人的基于统计的融合因子、SSPNet中突出特定尺度特征等方法.
   
   - **为什么特征融合后就可以更好的表示小目标特征了？**
   >特征融合有助于更好地表示小目标特征的原因主要有以下几点：
   **1.信息丰富性增强：** 融合不同深度或不同层级的特征能够将多个层次的信息结合起来，从而提供更丰富、更全面的视角。低层特征包含更多局部细节和定位信息，而高层特征包含更丰富的语义信息。将这些不同层次的信息融合在一起可以提供更全面的、更有利于小目标检测的特征表示。
   **2.增强鲁棒性：** 在面对光照变化、姿态变化或者小物体消失响应等问题时，单一层级的特征可能会受到较大影响。特征融合可以在一定程度上提高特征的鲁棒性，使得模型更能够适应不同场景下的小目标检测需求。
   **3.语义和定位的结合：** 通过将底层的定位信息与高层的语义信息相结合，特征融合能够实现更准确的定位和更高层次的语义理解。这对于小目标而言尤其重要，因为小目标往往具有较少的特征信息，融合不同层次的信息可以帮助更好地识别和定位这些目标。

总的来说，特征融合可以将不同层次、不同层级的信息结合起来，为小目标提供更全面、更准确的特征表示，从而改善小目标的检测效果。

##### conclusion
   特定尺度架构旨在以最合适的尺度处理小目标，而融合方法旨在弥合**金字塔层级**中不同级别特征之间的空间和语义差异。
   作者的目标是在特征的不同层次中提供更多语义信息，同时防止深层特征的影响过大而掩盖了小目标的原始响应。
   但实现这两者之间的平衡是个难题，因为要既强化低层特征的语义信息，又避免深层特征压制小目标的信息。这个问题需要仔细权衡和解决。
   - **金字塔层级**
   >在计算机视觉中，金字塔通常指的是由不同分辨率的图像组成的层级结构。金字塔级别则指的是这个金字塔结构中的不同层次或不同分辨率的层级。
   图像金字塔是一种常用的图像处理技术，它包含了同一图像的多个版本，这些版本具有不同的分辨率。金字塔结构通常由原始图像开始，然后通过降采样或上采样等方式生成一系列具有不同分辨率的图像。最常见的金字塔类型是高斯金字塔和拉普拉斯金字塔。
   在文中，提到了不同金字塔级别的特征。这指的是在一个图像金字塔结构中，不同层级或分辨率的特征图。在物体检测或图像处理中，这些不同级别的特征可以用于对不同尺度的目标进行检测或分析。
#### 3.3 Attention-Based Methods 基于注意力机制的方法
   为特征图的不同部分分配不同的权重，强调有价值的区域，抑制无关紧要的区域。这种方法可以用于突出小目标，因为小目标往往容易被背景和噪声模式所掩盖，从而在特征表示中部分减少了干扰。
#### 3.4 Feature-Imitation Methods 特征模拟方法
在小目标检测中，一个主要挑战是由于小目标的信息较少而导致的低质量特征表示。因此，**减轻这种低质量特征**表示问题的直接方式是通过**模拟**较大目标的区域特征来**丰富**小目标的特征表示。

方法分为两类：**相似性学习和基于超分辨率的特征模拟框架。**  

这些方法旨在通过模仿较大目标的特征来增强小目标的特征表示，从而提高小目标检测的准确性和鲁棒性。
##### *Similarity Learning-Based Methods 基于相似性学习的方法*
- 即在通用检测器上施加额外的相似性约束，以弥合小目标和大目标之间的特征表示差距。
- 受人类视觉理解机制的记忆过程启发，通过大尺度行人的记忆来优化整体架构，引导小尺度和大尺度行人特征的相似性。
##### *Super-Resolution-Based Frameworks 基于超分辨率的框架*
- 旨在恢复小目标的扭曲结构，而不仅仅是放大它们模糊的外观。
- 
## V. EXPERIMENTS
## V. EXPERIMENTS
### A. Evaluation Protocol
作者采用了与 COCO 数据集中相似的评估协议，并使用平均精度（AP）作为评估检测器性能的主要指标。
具体来说，他们计算了在小目标上介于 0.5 和 0.95 之间的 10 个 IoU（Intersection over Union）阈值的 AP 并对其进行平均，得到整体的 AP。
### A. Evaluation Protocol 评估目标检测器性能
>作者采用了与 COCO 数据集中相似的评估协议，并使用平均精度（AP）作为评估检测器性能的主要指标。具体来说，他们计算了在小目标上介于 0.5 和 0.95 之间的 10 个 IoU（Intersection over Union）阈值的 AP 并对其进行平均，得到整体的 AP。
#### 1.计算精度

*IoU 是目标检测中用于衡量预测边界框和真实边界框重叠程度的指标。在这里，作者使用了多个 IoU 阈值来评估小目标的检测效果。具体步骤如下:*
- **选择 IoU 阈值范围**： 选取了从 0.5 到 0.95 之间共 10 个不同的 IoU 阈值。
- **计算每个阈值下的精度（Precision）**： 对于每个 IoU 阈值，系统会对预测框和真实框之间的重叠程度进行比较。如果两个框的 IoU 大于设定的阈值，则认为该预测是正确的检测结果。根据这些判断，计算每个 IoU 阈值下的精度值。
- **计算平均精度（AP）**： 将这 10 个 IoU 阈值下计算得到的精度值进行平均，得到小目标的平均精度（AP）。这样的计算方式能够综合考虑不同 IoU 阈值下的检测性能，提供了更全面的评估指标。

>这种方法允许评估模型在小目标检测中在不同重叠度要求下的性能表现，因为较高的 IoU 阈值要求表示更严格的检测要求，而较低的 IoU 阈值可能更宽松。综合考虑多个阈值下的表现可以提供更全面的模型评估。
#### 2.为什么较高的 IoU 阈值要求表示更严格的检测要求？
- **更高的重叠要求**： 当 IoU 阈值较高时（例如，0.9），意味着预测框和真实框必须高度重叠才被认为是正确的检测结果。这种要求使得检测框需要几乎完全与真实框重叠，对检测器的精度和准确性提出了较高的挑战。

- **更严格的真实性要求**： 较高的 IoU 阈值可能需要更精确地捕获目标的位置和形状。这就要求检测器的预测结果必须准确地匹配目标的真实形态，不能容忍太大的偏差或误差。


这种方法允许评估模型在小目标检测中在不同重叠度要求下的性能表现，因为较高的 IoU 阈值要求表示更严格的检测要求，而较低的 IoU 阈值可能更宽松。综合考虑多个阈值下的表现可以提供更全面的模型评估。
此外，他们分别计算了在单个 IoU 阈值为 0.5 和 0.75 时的 AP50 和 AP75。为了突显对尺寸有限目标的关注，还展示了四个区域子集的 AP，分别是 APeS、APrS、APgS 和 APN。
>此外，他们分别计算了在单个 IoU 阈值为 0.5 和 0.75 时的 AP50 和 AP75。为了突显对尺寸有限目标的关注，还展示了四个区域子集的 AP，分别是 APeS、APrS、APgS 和 APN。
#### 3. 四个特定的区域子集的平均精度（AP）
这些子集是为了强调对尺寸有限目标的关注而设定的。
@@ -179,9 +180,172 @@ the main contributions of this paper
- APN： 这个指标可能代表着正常尺寸目标（Normal），即在图像中尺寸大小适中的目标。

通过计算和比较这些不同尺寸范围内的目标检测精度（使用平均精度作为指标），可以评估模型在不同尺寸的目标上的表现。这种分解可以帮助评估目标检测器在特定尺寸范围内的性能，以便更好地理解和比较其对不同尺寸目标的适应能力。
### B. Implementation Details 具体实现细节

>作者使用了 mmdetection5 和 mmrotate6工具包分别对 SODA-D 和 SODA-A 数据集进行实验。由于 GPU 内存有限，直接将 SODA 中的高分辨率图像输入深度模型是不可行的，因此他们将原始图像裁剪成一系列大小为 800 × 800 的补丁，并使用步长为 650。
#### 1.步长为650？
- 步长（stride）为650指的是在图像裁剪过程中的**移动间隔**。这个值表示裁剪图像时，每次移动的像素数量。
- 假设有一个原始图像，作者将其裁剪成一系列大小为800x800的图像块（也称为补丁）。步长为650意味着在裁剪第一个800x800图像块后，下一个图像块的起始位置向右或向下移动650个像素，而不是通常的像素一个一个地移动。

- 这样的设置可以确保图像覆盖更多的区域，并且允许部分重叠，因为在每次移动时，并不是完全跳过整个图像的800x800区域，而是**在部分重叠的基础上移动**。这有助于模型在训练和测试过程中更全面地学习和检测图像中的特征和目标。

>这些补丁在训练和测试期间将被调整为 1200 × 1200，这在一定程度上可以缓解特征提取阶段的信息损失.
#### 2.调整尺寸的过程(两种情况)

- **放大和裁剪**：原始图像可能被放大到1200x1200大小，然后在训练和测试时将其裁剪成固定的1200x1200大小的图像块。这样做可能会损失一些原始图像边缘的信息，但也确保了模型在训练和测试期间接收相同尺寸的输入。

- **重新采样或插值**：这种情况下，图像的像素值可能被重新计算以适应新的尺寸，但并没有增加原始图像的分辨率或捕捉到更多的细节。(可以帮助调整图像的大小而不失真或损失太多细节。)
在深度学习任务中，当模型对输入图像大小有特定的要求时，使用重新采样或插值可以将图像调整为所需的尺寸，以确保模型能够接受正确尺寸的输入进行训练或推理。

>需要注意的是，基于补丁的检测结果将首先映射到原始图像上，然后进行非极大值抑制（NMS）以剔除多余的预测。作者使用了 4 个 NVIDIA GeForce RTX 3090 GPU 来训练模型，将SODA-D 实验中的批量大小设置为 8，将SODA-A 设置为 4，其中角度范围为 [π/2, π/2)。在训练期间仅使用了随机翻转进行数据增强，更多细节和超参数设置请参考附录中的 C.1 和 D.1 节，可在线获取。
#### 3. 非极大值抑制（NMS）
非极大值抑制（NMS）是一种用于目标检测和边界框回归的常见技术。在目标检测中，神经网络往往会产生多个重叠的边界框，每个框对应可能存在的目标。NMS 的目标是从这些重叠的候选边界框中选择最佳的一个，以去除冗余的检测结果。

NMS 的工作原理通常如下：

- 得分排序： 首先，根据预测边界框的得分（通常是分类得分或者置信度分数）对所有检测结果进行排序，从高到低排列。
- 选取最佳框： 选择得分最高的边界框，并将其作为最终输出的一个框，同时将其与其他边界框进行比较。
- 移除重叠框： 对于剩余的边界框，检查它们与已选中的最佳框的重叠程度（通常是IoU），如果重叠超过设定的阈值，则将这些边界框移除，只保留最佳的边界框。
- 重复步骤： 继续重复这个过程，选择下一个得分次高的边界框，并重复以上步骤，直到处理完所有的边界框。

这个过程确保了在同一目标上有多个边界框预测时，只保留最准确的一个，同时去除掉其他高度重叠的、重复的边界框。这有助于减少重复检测，并提高目标检测的准确性。

#### 4. 学习网址
https://github.com/open-mmlab/mmdetection
https://github.com/open-mmlab/mmrotate
https://github.com/open-mmlab/OpenMMLabCourse
https://github.com/open-mmlab/OpenMMLabCourse

### C. Results Analysis on SODA-D 对SODA-D测试系统的结果分析

>在本节中，我们对SODA-D数据集上的几种代表性方法进行了严格的评估，并在结果的基础上提供了深入的分析。此外，我们还进行了一些实验来研究标签分配和损失设计对SOD的影响。更多的细节可以在章节中找到C.2和附录中的C.3，可在线获得。
#### 1) Benchmarking Results 基准测试结果
在这一部分的第一项是针对 SODA-D 测试集上 12 种代表性方法的结果报告（Table VI）。根据报告，可以发现以下一些情况和发现：

>- Faster RCNN [1] 在 AP 上得分为 28.9%，而 Cascade RCNN [166] 利用级联结构获得了最佳性能，达到了 31.2% 的 AP 和令人印象深刻的 27.8% 的 AP75，在性能上稳定地超过其他检测器。
>- RFLA [63] 在 Faster RCNN 的基础上获得了 29.7% 的 AP，尽管与此同时，APeS 实际上下降了 0.7 个百分点，表明设计的分配方式可能不适合那些尺寸极小的实例。
>- RetinaNet [3] 在 AP 上得分为 28.2%，接近 Faster RCNN，但在 APeS 方面存在很大差距（11.9% 对比 13.9%），这表明错配问题在极小目标上带来了显著影响。
>- RepPoints [168] 的整体 AP 是 28.0%，但在 APeS 指标上（10.1%）远远落后于 Faster RCNN 和 RetinaNet，暗示**相对于框表示法，点表示法在小目标上可能并不是一个好的选择，但对大目标具有潜力。**
##### 1. 如何理解“相对于框表示法，点表示法在小目标上可能并不是一个好的选择，但对大目标具有潜力”？
主要基于两个方面的对比：
- APeS 指标的差异： 在作者提供的评估中，RepPoints 方法在整体 AP 方面表现为 28.0%，但在针对小目标的评估中，使用了 APeS 指标，得分仅为 10.1%。这种差异性可能表明，尽管该方法在整体上可能表现良好，但在小目标上的性能明显较差。

- 相对于其他方法的对比： 文中提到 RepPoints 在小目标上的表现远远落后于 Faster RCNN 和 RetinaNet。Faster RCNN 和 RetinaNet 通常使用边界框（框表示法）进行目标检测，而 RepPoints 使用了点表示法。RepPoints 方法相对于这些使用框表示法的方法在小目标上的性能差异可能暗示了使用点表示法对小目标的定位和检测效果不佳。

>- ATSS [169] 在 SODA-D 测试集上可以达到 26.8% 的 AP，优于 FCOS [4]（23.9%），但在极小目标上表现糟糕（6.9%），这可能部分源于数据集的遮挡挑战。
>- CenterNet [47] 和 CornerNet [51] 分别只获得了 21.5% 和 24.6% 的 AP，甚至经过更多的训练迭代，它们的性能明显低于基于锚框的方法，尤其是在极小和相对小的目标上。
>- YOLOX [167] 在与其他基于锚点的方法相比可以获得竞争性结果（26.7% AP 和 13.6% APeS），但在大面积目标上有困难。
>- Sparse RCNN [170] 可以达到 24.2% 的 AP，与 FCOS 相媲美。而 Deformable DETR [52] 利用多尺度可变形注意力减少编码器中的高计算量，并在更多训练迭代中实现高分辨率特征访问，但只达到了 19.2% 的 AP，明显落后于其他竞争对手，甚至在更多训练迭代中仍有较大差距。这种性能差距可能揭示了稀疏查询范式不能充分覆盖小目标的情况。
综合这些观察结果，不同的检测器在不同大小的目标上表现出不同的优势和不足。有些方法在大目标上表现出色，而另一些则在小目标检测上更为优秀，这些评估和发现对于理解和优化目标检测器的性能具有重要意义
##### 2.它们是什么，有什么区别？

这些代表性方法通常是不同类型的目标检测器，它们采用了不同的架构、技术或方法来实现目标检测任务。这些检测器可能包括但不限于以下类型：

- 基于区域的检测器（Region-based Detectors）： 例如 Faster RCNN、Cascade RCNN 等，这些模型通常利用区域提议网络（Region Proposal Network，RPN）生成候选目标区域，然后对这些区域进行分类和边界框回归。

- 单阶段检测器（One-stage Detectors）： 例如 RetinaNet、YOLOX 等，这些模型直接在单个前向传播中执行目标分类和定位，不需要额外的区域提议步骤。

- 基于锚点或锚框的检测器（Anchor-based Detectors）： 这些模型使用预定义的锚点或锚框来进行目标检测，如 RetinaNet、Faster RCNN 等。

- 无锚点或自适应锚点的检测器（Anchor-free or Adaptive Anchors Detectors）： 例如 FCOS、CenterNet、CornerNet 等，这些模型不依赖于预定义的锚点，而是直接预测目标的位置。

这些方法在目标检测任务中采用不同的策略和技术，针对不同的应用场景或数据集特点，可能具有各自的优势和局限性。评估这些不同类型的检测器有助于了解它们在小目标检测任务中的性能和适用性。
#### 2) Category-Wise Results 针对不同类别的目标检测结果
>在表格 VII 中列出的各类别平均精度（AP）。特别指出，骑手（rider）、自行车（bicycle）、摩托车（motor）和交通摄像头（traffic-camera）的 AP 明显低于其他类别的情况。作者认为这种现象的根本原因有两方面：
>- **类别不平衡问题**： 比较这些类别与其他类别相比，这些类别的样本数量较少，例如，自行车类别只包含了 2560 个样本。类别不平衡可能导致模型对于样本较少的类别学习不充分，难以准确地识别这些类别的目标。
>- **有限的目标区域**： 例如，将近一半的交通摄像头对象具有小于 256 像素的区域，如图 4 所示。换句话说，这种现象验证了之前的发现，即当目标尺寸变小时，检测难度急剧增加。
>这些类别中样本数量较少或目标区域有限的特点可能导致模型在这些类别上的性能下降。类别不平衡可能导致模型倾向于学习更常见的类别，而无法很好地泛化到样本较少的类别。同时，对于具有有限区域的目标，模型可能更难以精确地检测和定位，从而降低了这些类别的检测性能。
#### 3) Baseline Detectors With Different Backbones 使用不同主干网络的基线检测器在目标检测任务中的性能比较
##### 1.主干网络
- **主干网络backbone network**是指构成神经网络骨架结构的部分，负责特征提取和表示。它是神经网络中的核心部分，负责从原始输入数据中学习并提取高层次的特征表示，以供后续的任务（8*如分类、目标检测、语义分割等**）使用。

- 主干网络通常由多个堆叠的卷积层（或其他类型的层）组成，这些层能够逐渐提取输入数据中的特征信息。这些网络会逐渐减少空间分辨率并增加通道数量，使得网络能够从原始输入中提取出更加抽象和有用的特征。

- 在目标检测任务中，主干网络扮演着重要角色，因为它**决定了模型对于输入图像的特征提取能力**。一些常见的主干网络包括 ResNet、VGG、EfficientNet、Swin Transformer 等。选择合适的主干网络对于目标检测任务的性能和准确性至关重要。

>- ResNet-50 和 ResNet-101 的对比： 相对于 ResNet-50，使用更深的 ResNet-101 **只带来了轻微的性能改善**，甚至在某些情况下性能下降（如 Cascade RCNN 和 RetinaNet）。这可能表明对于尺寸受限的对象来说，更深层次的模型并不一定更好。深层次模型中高度结构化的表示方式可能不太包含小目标的线索，因此在小目标检测任务中不够优化。
>- Swin-T 主干网络的性能提升： Swin-T [173] 主干网络对所有检测器都带来了显著的改进，尤其是对于 FCOS 方法，提升了 5.3 个百分点。这种出色的表现表明了采用了移位窗口方案（shifted-window scheme）对小目标具有强大的表示能力，并且对未来SOD的特征提取器设计有着重要启示。
>- ConvNext-T 主干网络的效果： 大多数以 ConvNext-T [174] 为主干网络的检测器实现了最佳性能，展现出对小目标的更精细表示的良好鲁棒性和潜力。
>强调了主干网络选择对目标检测器性能的影响。深度模型（如 ResNet-101）在处理尺寸受限的目标时可能不如预期，并且结构化表示在这方面可能不够优化。而采用了 Swin-T 或 ConvNext-T 等新颖的主干网络，对小目标的表示能力更强，对目标检测性能的提升更为显著。
##### 2. 它们有什么区别？
这些主干网络可能在结构、深度、参数量等方面存在一些差异，导致它们在目标检测任务中的性能表现不同。

- 深度和结构： 不同的主干网络可能拥有不同数量和类型的层，这决定了它们提取特征的复杂性和能力。例如，ResNet-50 和 ResNet-101 拥有不同的深度，其中 ResNet-101 更深，并且在某些情况下可能不一定带来性能提升。

- 参数量和计算复杂度： 不同的主干网络可能具有不同数量的参数和计算复杂度。有些网络可能参数更多，复杂度更高，这可能在一定程度上影响了其性能和训练速度。

- 特征表示能力： 不同的主干网络可能对于提取不同类型的特征有着不同的表现。一些网络可能更擅长提取纹理特征，而另一些则更适合提取语义信息或空间信息。

- 新型主干网络的特点： 文本中提到了一些新型的主干网络，比如 Swin-T 和 ConvNext-T。这些是最新的架构设计，采用了一些新的技术或结构，例如 Transformer 结构、特定的注意力机制等，以提高在目标检测任务中的性能。
#### 4) Qualitative Results 定性结果
>- 描述了 Cascade RCNN 在 SODA-D 测试集上的可视化结果，用图 10 来展示了这些结果。文章提到了两对图像，分别展示了目标检测在不同场景下的挑战和失败情况。
#####  Cascade RCNN
- Cascade RCNN是一种目标检测器，是基于区域的卷积神经网络（Region-based Convolutional Neural Network）的变体之一。它是对标准的Faster RCNN框架的改进，在处理难以识别的目标或具有复杂背景的图像时可能会有更好的表现。

- Cascade RCNN通过级联多个检测器来逐步提高目标检测的准确性。它的核心思想是**使用一系列级联的检测阶段，每个阶段都在前一个阶段的基础上进一步提高辨别性能**。每个阶段都会筛选出高置信度的候选框，然后将这些候选框传递到下一个级联阶段进行更精细的检测。

- 这种级联的方式使得模型可以对不同难度和尺度的目标进行更深入的学习和检测，因此在处理一些具有挑战性的场景（**例如复杂背景、部分遮挡或低光照等情况**）时可能具有更强的鲁棒性。


>- 第一对图像展示了在复杂背景和严重遮挡情况下的挑战。在这种场景下，目标检测器很难从小目标中学习到能够区分目标与背景的特征表示，并且倾向于将与背景相似的目标实例误认为是背景的一部分。此外，识别部分遮挡的目标实例也更加具有挑战性，检测器可能无法准确地识别这些部分被遮挡的目标。
>- 第二对图像展示了在低光照条件下的检测结果。在这种情况下，目标检测器难以识别处于阴影下的目标实例，更不用说精确地预测它们的边界框了。这表明目标检测在低光条件下可能会遇到较大的挑战，导致检测失败或者精度降低。
>- 总体而言，这段文字描述了在复杂背景、严重遮挡和低光照等不同情况下，Cascade RCNN 目标检测器所面临的挑战。这些情况可能导致目标检测失败，使其难以准确识别和定位目标对象。
### D. Results Analysis on SODA-A 对SODA-A测试系统的结果分析
#### 1) Benchmarking Results 基准结果

##### 1. Schedule (来自小字)
- 训练计划（Schedule）： 这里的“Schedule”指的是模型训练期间的epoch设置，epoch表示将整个训练数据集完整地在模型中经过一次训练的次数。
- ’1×’代表12个epochs： 这里的’1×’表示训练时的时间表设置，特指训练的epoch数量。在这个场景下，’1×’指的是模型在训练过程中总共经历了12个epochs。
- 50e 代表50个epochs

>在SODA-A测试集上的基准结果展示了九种代表性的面向定向物体检测方法在不同指标下的表现：
>- RoI Transformer：达到了最高的36.0% AP，其成功归因于强大的提案生成器，能够产生旋转提案以保证小目标的高召回率。
##### 2.提案生成器
指的是能够生成高质量目标提案（即候选框或区域）的组件或方法。在目标检测中，**提案生成器负责生成可能包含目标的候选区域，以便后续的目标分类和定位。**
一个强大的提案生成器在面对复杂场景、小目标或密集目标时能够表现出色。它应该能够：
- **高召回率**： 生成尽可能多的包含真实目标的提案，确保召回尽可能多的真实目标。

- **高质量**： 生成的提案应该与真实目标边界尽可能接近，减少误检测和漏检测的情况。

- **适应不同形状和尺度的目标**： 在面对各种形状、大小和方向的目标时，能够生成相应的准确提案。

在文中所提及的RoI Transformer方法中，其强大的提案生成器指的是RRoI Learner（方法中的一个关键组件）所产生的旋转提案。这些提案针对小目标具有高召回率，并且能够旋转适应目标的不同方向，从而在面对定向物体检测任务时表现出色。

>- Rotated Faster RCNN：通过在标准的Faster RCNN基础上输出额外的角度预测，取得了32.5%的AP，验证了这种方法的鲁棒性。
>- Oriented RCNN：在整体AP上达到了34.4%，其高效的定向RPN生成高质量的提案，且参数增长微小。
>- Gliding Vertex 和 DODet：这两种方法都采用了新颖的面向对象的表示方法，分别达到了31.7%和31.6%的AP。它们的性能相近，但在不同类别上的表现可能归因于不同的表示方法。
>- Rotated RetinaNet：作为单阶段检测器，达到了26.8%的AP，相较于两阶段方法略显落后。这是因为SODA-A包含大量极小目标，而单阶段方法对此表现不佳。
>- 2A-Net：通过特征对齐模块缓解了不对齐问题，达到了28.3%的AP，但AP75指标下降了3.3个百分点，可能以后续回归准确性为代价。
##### 3.特征对齐模块
通常指的是在目标检测或图像处理任务中用于调整或对齐特征表示的组件或方法。
在目标检测中，特征对齐模块可能采取以下方式：

- 空间对齐： 在特征图上进行空间级别的对齐，确保不同位置的特征能够保持一致性。这可以通过空间金字塔池化、空洞卷积等操作来实现。

- 尺度对齐： 对特征图进行尺度变换或尺度归一化，以确保不同尺度的特征能够在模型中有效地使用。这可能涉及到尺度变换层或尺度注意力机制等。

- 通道对齐： 调整或对齐特征图中不同通道之间的表示，以提高特征的可解释性和区分度。这可以通过通道注意力机制、通道级别的归一化或卷积核的组合等方式实现。

- 形状对齐： 对特征表示进行形状上的调整，使得不同形状的目标在特征表示上更为一致。这可能涉及到形状对齐网络或形状变换模块等方法。
这些特征对齐模块的设计旨在提高模型对于特征表示的一致性和准确性，从而改善目标检测模型的性能和鲁棒性。特征对齐模块通常作为目标检测模型的一个组成部分，用于对提取的特征进行进一步处理和优化。
>- Oriented RepPoints：使用点集表示，在SODA-A的空中场景中表现稍逊，达到26.3%的AP，特别是对于具有大长宽比的目标。
>- DHRec：采用两个水平矩形编码多向定向目标，解决了不连续性问题，达到了30.1%的AP，在参数最少的单阶段方法中表现显著优越。
##### 4. 水平矩形编码多向定向目标
https://github.com/lightbillow/DHRec
- 传统的目标检测算法通常使用矩形边界框来表示目标位置和边界，但是在处理多向定向的目标时，这种表示可能会存在不连续性，即无法很好地适应目标的多个方向。
- 它使用两个水平的矩形来编码多向定向目标。这种方法可能会更好地适应目标的多种方向，通过组合这两个水平矩形来表示多向定向目标，从而解决了在传统表示中可能存在的不连续性问题。

>- 这些结果显示了不同方法在面向定向物体检测任务中的表现差异。RoI Transformer在小目标召回率上表现突出，Rotated Faster RCNN验证了其鲁棒性，而一些方法则面临着处理小目标或特定场景下定向物体检测的挑战。同时，对于密集堆积的目标，高质量的提案对于检测至关重要

#### 2) Category-Wise Results 

>- **直升机类别的AP明显低于其他类别**： 这是由于直升机类别的**目标实例数量有限**.由于数据中直升机目标数量较少，模型在这一类别上的检测性能相对较低。
>- **大型车辆和具有纵向结构的容器对回归分支的挑战**： 这两个类别的目标具有纵向或纵向结构，这可能对某些基线算法的回归分支构成挑战，特别是对于Oriented RepPoints。这意味着在这些类别中，模型可能在准确回归目标的边界框方面遇到了一些困难。
>- **Gliding Vertex和DODet在不同类别上表现不同**： 虽然Gliding Vertex和DODet两种方法在整体上表现相近，但在不同类别上的表现存在差异。这可能归因于它们对于定向物体的不同表示方法，导致它们在不同类别上的性能差异。

- **Gliding Vertex（滑动顶点）**： 这是一种用于定向目标检测的方法，其主要思想是利用四个滑动顶点来表示目标的边界。通过学习这四个顶点的位置偏移，模型可以更准确地定位和描述目标的边界，特别是针对具有定向形状的目标。

- **DODet（Direction-aware Object Detection）**： 这是另一种定向目标检测的方法，其特点在于考虑了目标的方向信息。DODet利用目标的方向、长宽比和区域等信息来表示目标，以便更好地适应和识别具有方向性的目标对象，比如倾斜的矩形或具有定向性的物体。

这两种方法都致力于解决传统目标检测方法中忽视的**定向目标检测问题**。它们的目标是提高模型对于具有方向性或定向形状的目标的识别和定位能力，通过引入定向信息来改善目标检测的准确性和鲁棒性。
#### 3) Baseline Detectors With Different Backbones
这段描述了在采用不同主干网络的基线检测器中的性能表现情况，这些基线检测器被用于 SODA-A 数据集。

>- ResNet-101性能略有改进甚至下降： 类似于在SODA-D数据集上的结果，ResNet-101主干网络在SODA-A上表现出性能略微提升，甚至下降。

>- 使用Swin-T主干网络带来两种不同的现象：
>1. 对于基于RPN(（Region Proposal Network，区域建议网络）)的检测器：Swin-T能够带来不同程度的性能提升（从0.1点到1.2点）。
>2. 对于无RPN结构的检测器：Swin-T导致性能大幅下降（对于Rotated RetinaNet下降了-3.5点，对于S2A-Net下降了-2.3点）。这与在SODA-D上的结果完全不同。
##### 1.RPN 与 主干网络
RPN（Region Proposal Network）和主干网络在目标检测中起着不同的作用：
1. RPN（Region Proposal Network）：
   - RPN是用于生成候选目标区域的神经网络模块。它负责在图像中提出可能包含目标的候选区域，这些区域会被送入后续的检测网络进行进一步的处理。*（两阶段目标检测方法提到）*
   - RPN的作用是从输入图像中提取感兴趣的区域，并为这些区域提供建议（或称为候选区域），以便进一步进行目标检测。

2. 主干网络（Backbone Network）：
   - 主干网络是用于特征提取的深度神经网络结构，它负责从原始图像中提取特征表示。
   - 主干网络通常由一系列卷积层组成，能够对输入图像进行多层次的特征提取和抽象，从而获得图像的高级特征表示。

这两个组件通常结合在一起构成端到端的目标检测模型。主干网络负责从图像中提取特征，而RPN则基于这些特征提供候选区域。然后，这些提出的区域被送入检测网络中进行目标分类和边界框回归，最终完成目标检测任务。

>- 分析差异的可能原因： 作者推测这种差异可能源自Swin-T在应对密集分布时的能力有限。特别是在检测器面临不对齐问题时，尤其是在那些**物体极其靠近的情况下**，Swin-T的能力受到了限制。
>- ConvNext-T主干网络的趋势类似于Swin-T： 对于无RPN结构的检测器，ConvNext-T主干网络也面临更严重的不对齐问题，因为目标区域与水平先验之间存在巨大差异。
##### 2.如何理解产生不对齐问题和巨大差异？

水平先验框是**预先定义的固定形状和尺寸的边界框**，用于在图像中建议可能存在目标的区域。然而，有些目标可能具有不同于水平先验框的形状或方向，这导致了目标区域与这些水平先验框之间存在较大的差异。

这种差异可能导致以下问题：

- 不对齐问题： 目标区域的形状、方向与水平先验框不匹配，可能导致边界框的不准确性，使得模型难以准确预测目标的位置和形状。
- 误检问题： 对于具有非常规形状或方向的目标，可能无法很好地用水平先验框进行表示，导致模型难以检测到这些目标，或者产生错误的检测结果。
  
这些结果表明不同主干网络对于目标检测在SODA-A数据集上的性能影响是不同的，特别是在处理密集分布和不对齐问题时，不同的主干网络可能会导致截然不同的效果。
#### 4) Qualitative Results 定性结果
在SODA-D测试集上使用Oriented RCNN的定性结果可视化。

>- **微小目标检测困难**： 第一对图展示了微小目标的检测结果，只有极少数微小目标被检测到。这表明对于当前的检测器来说，检测微小目标是一个巨大的挑战，即使在性能较好的情况下也很难完全检测到这些微小目标。

>- **低对比度目标检测困难**： 第二对图展示了低对比度目标的检测结果。例如，飞机目标在视觉特征上与背景相似，导致模型将其错误地识别为直升机。由于模糊的背景和目标之间视觉特征的相似性，模型可能更倾向于使用视觉外观进行识别，而不是保留的细节信息，这可能会导致假阳性和错误的预测（如容器的预测结果）。

总体而言，这些定性结果显示了目标检测在SODA-D数据集上面临的一些挑战，特别是针对微小目标和低对比度目标。这些情况下，即使对于性能较好的检测器，也存在着识别和定位错误的可能性。
11.22